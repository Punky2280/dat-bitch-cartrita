// packages/backend/src/agi/consciousness/LangChainCoreAgent.js

/**
 * LangChain-powered CoreAgent that replaces the complex MCP orchestration
 * with a simpler, more reliable tool-based approach while maintaining
 * Cartrita's personality and all existing capabilities
 */

const LangChainOrchestrator = require('../orchestration/LangChainOrchestrator');
const AgentToolRegistry = require('../orchestration/AgentToolRegistry');
const db = require('../../db');

class LangChainCoreAgent {
  constructor() {
    this.orchestrator = new LangChainOrchestrator();
    this.toolRegistry = new AgentToolRegistry(this.orchestrator);
    this.initialized = false;
    
    // Performance metrics
    this.metrics = {
      requests_processed: 0,
      successful_responses: 0,
      failed_responses: 0,
      tools_used_total: 0,
      average_response_time: 0,
      start_time: Date.now()
    };
  }

  /**
   * Initialize the LangChain-powered core agent
   */
  async initialize() {
    try {
      console.log('[LangChainCoreAgent] Initializing...');
      
      // Register all agents as LangChain tools
      await this.toolRegistry.registerAllAgents();
      
      // Initialize the LangChain orchestrator
      const success = await this.orchestrator.initialize();
      
      if (success) {
        this.initialized = true;
        console.log('[LangChainCoreAgent] Successfully initialized with LangChain orchestration');
        return true;
      } else {
        throw new Error('Failed to initialize LangChain orchestrator');
      }
      
    } catch (error) {
      console.error('[LangChainCoreAgent] Initialization failed:', error);
      this.initialized = false;
      return false;
    }
  }

  /**
   * Generate response using LangChain orchestration
   */
  async generateResponse(prompt, language = 'en', userId = null) {
    const startTime = Date.now();
    this.metrics.requests_processed++;

    try {
      console.log(`[LangChainCoreAgent] Processing request: "${prompt}" (user: ${userId})`);

      if (!this.initialized) {
        throw new Error('LangChain core agent not initialized');
      }

      // Get user settings for personalization
      const userSettings = await this.fetchUserSettings(userId);
      
      // Add user context to prompt if available
      let contextualPrompt = prompt;
      if (userSettings && Object.keys(userSettings).length > 0) {
        const personalityContext = this.buildPersonalityContext(userSettings);
        contextualPrompt = `${prompt}\n\nUser preferences: ${personalityContext}`;
      }

      // Decide whether to use tools or direct conversation
      const shouldUseLangChainTools = this.shouldUseLangChainTools(prompt);
      
      let result;
      if (shouldUseLangChainTools) {
        console.log('[LangChainCoreAgent] Using LangChain tool orchestration');
        result = await this.orchestrator.processRequest(contextualPrompt, language, userId);
      } else {
        console.log('[LangChainCoreAgent] Using direct conversation');
        result = await this.orchestrator.handleDirectConversation(contextualPrompt, language, userId);
      }

      // Update metrics
      const responseTime = Date.now() - startTime;
      this.updateMetrics(true, responseTime, result.tools_used?.length || 0);

      // Ensure result has proper format
      return {
        text: result.text || result,
        speaker: 'cartrita',
        model: result.model || 'cartrita-langchain',
        tools_used: result.tools_used || [],
        response_time_ms: responseTime,
        protocol_version: '2.0.0'
      };

    } catch (error) {
      console.error('[LangChainCoreAgent] Error generating response:', error);
      
      const responseTime = Date.now() - startTime;
      this.updateMetrics(false, responseTime, 0);

      // Return Cartrita-style error message
      return {
        text: this.getCartritalErrorMessage(),
        speaker: 'cartrita',
        model: 'langchain-fallback',
        error: true,
        response_time_ms: responseTime
      };
    }
  }

  /**
   * Determine if we should use LangChain tools or direct conversation
   */
  shouldUseLangChainTools(prompt) {
    // Simple heuristics to determine if tools are needed
    const toolKeywords = [
      'search', 'find', 'research', 'look up',
      'write', 'create', 'generate', 'draft',
      'code', 'program', 'debug', 'function',
      'joke', 'funny', 'humor', 'laugh',
      'schedule', 'calendar', 'appointment', 'meeting',
      'task', 'todo', 'organize', 'manage',
      'github', 'repository', 'repo',
      'art', 'creative', 'design', 'visual'
    ];

    const promptLower = prompt.toLowerCase();
    return toolKeywords.some(keyword => promptLower.includes(keyword));
  }

  /**
   * Fetch user settings from database
   */
  async fetchUserSettings(userId) {
    if (!userId) return null;
    
    try {
      const { rows } = await db.query(
        'SELECT sarcasm, verbosity, humor FROM user_settings WHERE user_id = $1',
        [userId]
      );
      
      if (rows.length > 0) {
        console.log(`[LangChainCoreAgent] Fetched settings for user ${userId}:`, rows[0]);
        return rows[0];
      }
    } catch (error) {
      console.error(`[LangChainCoreAgent] Error fetching settings for user ${userId}:`, error);
    }
    
    return { sarcasm: 5, verbosity: 'normal', humor: 'playful' };
  }

  /**
   * Build personality context from user settings
   */
  buildPersonalityContext(userSettings) {
    const { sarcasm = 5, verbosity = 'normal', humor = 'playful' } = userSettings;
    
    return `Sarcasm level ${sarcasm}/10, ${verbosity} verbosity, ${humor} humor style`;
  }

  /**
   * Get a Cartrita-style error message
   */
  getCartritalErrorMessage() {
    const errorMessages = [
      "Okay, my circuits just had a moment. Can you try that again?",
      "Something went sideways in my brain. Give me another shot at this.",
      "Technical difficulties on my end. What were you asking again?",
      "My processors are having a party without me. One more time?",
      "System hiccup. I'm back online - what do you need?"
    ];
    
    return errorMessages[Math.floor(Math.random() * errorMessages.length)];
  }

  /**
   * Update performance metrics
   */
  updateMetrics(success, responseTime, toolsUsed) {
    if (success) {
      this.metrics.successful_responses++;
    } else {
      this.metrics.failed_responses++;
    }
    
    this.metrics.tools_used_total += toolsUsed;
    
    // Update average response time
    const totalResponses = this.metrics.successful_responses + this.metrics.failed_responses;
    this.metrics.average_response_time = (
      (this.metrics.average_response_time * (totalResponses - 1) + responseTime) / totalResponses
    );
  }

  /**
   * Get status and metrics
   */
  getStatus() {
    const uptime = Date.now() - this.metrics.start_time;
    
    return {
      service: 'LangChainCoreAgent',
      initialized: this.initialized,
      uptime_ms: uptime,
      orchestrator_status: this.orchestrator?.getStatus(),
      tool_registry_status: this.toolRegistry?.getStatus(),
      metrics: {
        ...this.metrics,
        success_rate: this.metrics.requests_processed > 0 
          ? (this.metrics.successful_responses / this.metrics.requests_processed * 100).toFixed(2) + '%'
          : '0%'
      },
      version: '2.0.0'
    };
  }

  /**
   * Health check
   */
  isHealthy() {
    return this.initialized && this.orchestrator && this.toolRegistry;
  }

  /**
   * Graceful shutdown
   */
  async shutdown() {
    console.log('[LangChainCoreAgent] Shutting down...');
    this.initialized = false;
    // LangChain doesn't require explicit cleanup, but we can log final metrics
    console.log('[LangChainCoreAgent] Final metrics:', this.metrics);
  }
}

module.exports = LangChainCoreAgent;